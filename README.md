# **Lip2Text: Lip Reading Analysis of Audioless Video**

## Problem Statement  
Design and implement an artificial intelligence system capable of accurately transcribing spoken language from silent video footage by analyzing and interpreting lip movements. The system should:

1. Process video input without relying on audio data.  
2. Detect and isolate the speaker's face and lip region in each video frame.  
3. Extract and analyze lip movement patterns over time.  
4. Interpret these visual cues to infer the spoken words.  
5. Generate accurate text transcriptions or subtitles corresponding to the lip movements.  
6. Handle variations in lighting conditions, camera angles, and speaker characteristics.  
7. Operate in real-time or near real-time for practical applications.  
8. Achieve a level of accuracy comparable to human lip-reading abilities.

## Dataset  
[Click here to access the dataset]([https://drive.google.com/drive/....](https://drive.google.com/drive/folders/1kTHPTFt0TVk2ZUV0aR0oSoV_n_kMu3Wu?usp=drive_link
))  
